<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kafka on Foo Bar Baz</title>
    <link>https://abhirockzz.github.io/tags/kafka/</link>
    <description>Recent content in kafka on Foo Bar Baz</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Â© Abhishek Gupta, 2021</copyright>
    <lastBuildDate>Thu, 13 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://abhirockzz.github.io/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PostgreSQL pgoutput plugin for change data capture</title>
      <link>https://abhirockzz.github.io/posts/postgres-debezium-pgoutput/</link>
      <pubDate>Thu, 13 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://abhirockzz.github.io/posts/postgres-debezium-pgoutput/</guid>
      <description>Set up a Change Data Capture architecture on Azure using Debezium, Postgres and Kafka was a tutorial on how to use Debezium for change data capture from Azure PostgreSQL and send them to Azure Event Hubs for Kafka - it used the wal2json output plugin.</description>
    </item>
    
    <item>
      <title>Kafka on Kubernetes, the Strimzi way! (Part 4)</title>
      <link>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-4/</link>
      <pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-4/</guid>
      <description>Welcome to part four of this blog series! So far, we have a Kafka single-node cluster with TLS encryption on top of which we configured different authentication modes (TLS and SASL SCRAM-SHA-512), defined users with the User Operator, connected to the cluster using CLI and Go clients and saw how easy it is to manage Kafka topics with the Topic Operator.</description>
    </item>
    
    <item>
      <title>Kafka on Kubernetes, the Strimzi way! (Part 3)</title>
      <link>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-3/</link>
      <pubDate>Tue, 07 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-3/</guid>
      <description>Over the course of the first two parts of this blog series, we setup a single-node Kafka cluster on Kubernetes, secured it using TLS encryption and accessed the broker using both internal and external clients.</description>
    </item>
    
    <item>
      <title>Change Data Capture architecture using Debezium, Postgres and Kafka</title>
      <link>https://abhirockzz.github.io/posts/postgres-kafka-debezium-azure-cdc/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://abhirockzz.github.io/posts/postgres-kafka-debezium-azure-cdc/</guid>
      <description>Change Data Capture (CDC) is a technique used to track row-level changes in database tables in response to create, update and delete operations.</description>
    </item>
    
    <item>
      <title>Kafka on Kubernetes, the Strimzi way! (Part 2)</title>
      <link>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-2/</link>
      <pubDate>Wed, 17 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-2/</guid>
      <description>We kicked off the the first part of the series by setting up a single node Kafka cluster which was accessible to only internal clients within the same Kubernetes cluster, had no encryption, authentication or authorization and used temporary persistence.</description>
    </item>
    
    <item>
      <title>Kafka on Kubernetes, the Strimzi way! (Part 1)</title>
      <link>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-1/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-1/</guid>
      <description>Some of my previous blog posts (such as Kafka Connect on Kubernetes, the easy way!), demonstrate how to use Kafka Connect in a Kubernetes-native way.</description>
    </item>
    
    <item>
      <title>Data pipeline using MongoDB and Kafka Connect on Kubernetes</title>
      <link>https://abhirockzz.github.io/posts/mongodb-kafka-kubernetes/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://abhirockzz.github.io/posts/mongodb-kafka-kubernetes/</guid>
      <description>In Kafka Connect on Kubernetes, the easy way!, I had demonstrated Kafka Connect on Kubernetes using Strimzi along with the File source and sink connector.</description>
    </item>
    
  </channel>
</rss>
