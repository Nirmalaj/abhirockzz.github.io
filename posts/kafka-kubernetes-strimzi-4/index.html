<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Kafka on Kubernetes, the Strimzi way! (Part 4) - Abhishek&#39;s blog (work in progress)</title><link rel="icon" type="image/png" href=icons/myicon.png /><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="Kafka on Kubernetes, the Strimzi way! (Part 4)" />
<meta property="og:description" content="Welcome to part four of this blog series!" />
<meta property="og:type" content="article" />
<meta property="og:url" content="abhirockzz.github.io/posts/kafka-kubernetes-strimzi-4/" />
<meta property="article:published_time" content="2020-07-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-07-28T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Kafka on Kubernetes, the Strimzi way! (Part 4)"/>
<meta name="twitter:description" content="Welcome to part four of this blog series!"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="abhirockzz.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="abhirockzz.github.io/css/main.css" />
	<link rel="stylesheet" type="text/css" href="abhirockzz.github.io/css/custom.css" />
	<link rel="stylesheet" type="text/css" href="abhirockzz.github.io/css/dark.css" media="(prefers-color-scheme: dark)" />
	<link rel="stylesheet" type="text/css" href="abhirockzz.github.io/css/custom-dark.css" media="(prefers-color-scheme: dark)" />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
	<script src="abhirockzz.github.io/js/main.js"></script>
	<script src="abhirockzz.github.io/js/abc.js"></script>
	<script src="abhirockzz.github.io/js/xyz.js"></script>
	<script src="https://code.jquery.com/jquery-3.4.1.js"></script>
</head>

<body>
	<div class="container wrapper post">
		<div class="header">
	<base href="abhirockzz.github.io/">
	<h1 class="site-title"><a href="abhirockzz.github.io/">Abhishek&#39;s blog (work in progress)</a></h1>
	<div class="site-description"><h2>Mostly about Kafka, Databases, Kubernetes and other open source stuff</h2><nav class="nav social">
			<ul class="flat"><a href="https://github.com/abhirockzz/" title="Github"><i data-feather="github"></i></a><a href="https://twitter.com/abhi_tweeter" title="Twitter"><i data-feather="twitter"></i></a><a href="https://www.linkedin.com/in/abhirockzz/" title="LinkedIn"><i data-feather="linkedin"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="abhirockzz.github.io/">Home</a>
			</li>
			
			<li>
				<a href="abhirockzz.github.io/posts">All posts</a>
			</li>
			
			<li>
				<a href="abhirockzz.github.io/about">About</a>
			</li>
			
			<li>
				<a href="abhirockzz.github.io/books">Books</a>
			</li>
			
			<li>
				<a href="abhirockzz.github.io/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post-header">
			<h1 class="title">Kafka on Kubernetes, the Strimzi way! (Part 4)</h1>
			<div class="meta">Posted at &mdash; Jul 28, 2020</div>
		</div>

		<div class="markdown">
			<p>Welcome to part four of this blog series! So far, we have a Kafka single-node cluster with TLS encryption on top of which we configured different authentication modes (<code>TLS</code> and <code>SASL SCRAM-SHA-512</code>), defined users with the User Operator, connected to the cluster using CLI and Go clients and saw how easy it is to manage Kafka topics with the Topic Operator. So far, our cluster used <code>ephemeral</code> persistence, which in the case of a single-node cluster, means that we will lose data if the Kafka or Zookeeper nodes (<code>Pod</code>s) are restarted due to any reason.</p>
<p>Let&rsquo;s march on! In this part we will cover:</p>
<ul>
<li>How to configure Strimzi to add persistence for our cluster:</li>
<li>Explore the components such as <code>PersistentVolume</code> and <code>PersistentVolumeClaim</code></li>
<li>How to modify the storage quality</li>
<li>Try and expand the storage size for our Kafka cluster</li>
</ul>
<blockquote>
<p>The code is available on GitHub - <a href="https://github.com/abhirockzz/kafka-kubernetes-strimzi/">https://github.com/abhirockzz/kafka-kubernetes-strimzi/</a></p>
</blockquote>
<h2 id="what-do-i-need-to-go-through-this-tutorial">What do I need to go through this tutorial?</h2>
<p><code>kubectl</code> - <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>
<p>I will be using <a href="https://docs.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=devto-blog-abhishgu">Azure Kubernetes Service (AKS)</a> to demonstrate the concepts, but by and large it is independent of the Kubernetes provider. If you want to use <code>AKS</code>, all you need is a <a href="https://docs.microsoft.com/azure/?WT.mc_id=devto-blog-abhishgu">Microsoft Azure account</a> which you can <a href="https://azure.microsoft.com/free/?WT.mc_id=devto-blog-abhishgu">get for FREE</a> if you don&rsquo;t have one already.</p>
<blockquote>
<p>I will not be repeating some of the common sections (such as Installation/Setup (Helm, Strimzi, Azure Kubernetes Service), Strimzi overview) in this or subsequent part of this series and would request you to <a href="https://dev.to/azure/kafka-on-kubernetes-the-strimzi-way-part-1-57g7">refer to part one</a></p>
</blockquote>
<h2 id="add-persistence">Add persistence</h2>
<p>We will start off by creating a persistent cluster. Here is a snippet of the specification (you can access the complete YAML <a href="https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-4/kafka-persistent.yaml">on GitHub</a>)</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yml" data-lang="yml"><span style="color:#268bd2">apiVersion</span>: kafka.strimzi.io/v1beta1
<span style="color:#268bd2">kind</span>: Kafka
<span style="color:#268bd2">metadata</span>:
  <span style="color:#268bd2">name</span>: my-kafka-cluster
<span style="color:#268bd2">spec</span>:
  <span style="color:#268bd2">kafka</span>:
    <span style="color:#268bd2">version</span>: <span style="color:#2aa198">2.4.0</span>
    <span style="color:#268bd2">replicas</span>: <span style="color:#2aa198">1</span>
    <span style="color:#268bd2">storage</span>:
      <span style="color:#268bd2">type</span>: persistent-claim
      <span style="color:#268bd2">size</span>: 2Gi
      <span style="color:#268bd2">deleteClaim</span>: <span style="color:#cb4b16">true</span>
....
  <span style="color:#268bd2">zookeeper</span>:
    <span style="color:#268bd2">replicas</span>: <span style="color:#2aa198">1</span>
    <span style="color:#268bd2">storage</span>:
      <span style="color:#268bd2">type</span>: persistent-claim
      <span style="color:#268bd2">size</span>: 1Gi
      <span style="color:#268bd2">deleteClaim</span>: <span style="color:#cb4b16">true</span>
</code></pre></div><p>The key things to notice:</p>
<ul>
<li><code>storage.type</code> is <code>persistent-claim</code> (as opposed to <code>ephemeral</code>) in <a href="https://github.com/abhirockzz/kafka-kubernetes-strimzi/blob/master/part-2/kafka.yaml#L20">previous examples</a></li>
<li><code>storage.size</code> for Kafka and Zookeeper nodes is <code>2Gi</code> and <code>1Gi</code> respectively</li>
<li><code>deleteClaim: true</code> means that the corresponding <code>PersistentVolumeClaim</code>s will be deleted when the cluster is deleted/un-deployed</li>
</ul>
<blockquote>
<p>You can take a look at the reference for <code>storage</code> <a href="https://strimzi.io/docs/operators/master/using.html#type-PersistentClaimStorage-reference">https://strimzi.io/docs/operators/master/using.html#type-PersistentClaimStorage-reference</a></p>
</blockquote>
<p>To create the cluster:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-4/kafka-persistent.yaml
</code></pre></div><p>Let&rsquo;s see the what happens in response to the cluster creation</p>
<h2 id="strimzi-kubernetes-magic">Strimzi Kubernetes magic&hellip;</h2>
<p><a href="https://strimzi.io/">Strimzi</a> does all the heavy lifting of creating required Kubernetes resources in order to operate the cluster. We covered most of these in <a href="https://dev.to/azure/kafka-on-kubernetes-the-strimzi-way-part-1-57g7">part 1</a> - <code>StatefulSet</code> (and <code>Pods</code>), <code>LoadBalancer</code> Service, <code>ConfigMap</code>, <code>Secret</code> etc. In this blog, we will just focus on the persistence related components - <code>PersistentVolume</code> and <code>PersistentVolumeClaim</code></p>
<blockquote>
<p>If you&rsquo;re using Azure Kubernetes Service (AKS), this will create an <a href="https://docs.microsoft.com/azure/virtual-machines/windows/managed-disks-overview?WT.mc_id=devto-blog-abhishgu">Azure Managed Disk</a> - more on this soon</p>
</blockquote>
<p>To check the <code>PersistentVolumeClaim</code>s</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl get pvc


NAME                                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
data-my-kafka-cluster-kafka-0       Bound    pvc-b4ece32b-a46c-4fbc-9b58-9413eee9c779   2Gi        RWO            default        94s
data-my-kafka-cluster-zookeeper-0   Bound    pvc-d705fea9-c443-461c-8d18-acf8e219eab0   1Gi        RWO            default        3m20s
</code></pre></div><p>&hellip; and the <code>PersistentVolume</code>s they are <code>Bound</code> to</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl get pv


NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                       STORAGECLASS   REASON   AGE
pvc-b4ece32b-a46c-4fbc-9b58-9413eee9c779   2Gi        RWO            Delete           Bound    default/data-my-kafka-cluster-kafka-0       default                 107s
pvc-d705fea9-c443-461c-8d18-acf8e219eab0   1Gi        RWO            Delete           Bound    default/data-my-kafka-cluster-zookeeper-0   default                 3m35s
</code></pre></div><blockquote>
<p>Notice that the disk size is as specified in the manifest ie. <code>2</code> and <code>1</code> Gib for Kafka and Zookeeper respectively</p>
</blockquote>
<h3 id="where-is-the-data">Where is the data?</h3>
<p>If we want to see the data itself, let&rsquo;s first check the <code>ConfigMap</code> which stores the Kafka server config:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#b58900">export</span> <span style="color:#268bd2">CLUSTER_NAME</span><span style="color:#719e07">=</span>my-kafka-cluster
kubectl get configmap/<span style="color:#2aa198">${</span><span style="color:#268bd2">CLUSTER_NAME</span><span style="color:#2aa198">}</span>-kafka-config -o yaml
</code></pre></div><p>In <code>server.config</code> section, you will find an entry as such:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#586e75">##########</span>
<span style="color:#586e75"># Kafka message logs configuration</span>
<span style="color:#586e75">##########</span>
log.dirs<span style="color:#719e07">=</span>/var/lib/kafka/data/kafka-log<span style="color:#2aa198">${</span><span style="color:#268bd2">STRIMZI_BROKER_ID</span><span style="color:#2aa198">}</span>
</code></pre></div><p>This tells us that the Kafka data is stored in <code>/var/lib/kafka/data/kafka-log${STRIMZI_BROKER_ID}</code>. In this case <code>STRIMZI_BROKER_ID</code> is <code>0</code> since we all we have is a single node</p>
<p>With this info, let&rsquo;s look the the Kafka <code>Pod</code>:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#b58900">export</span> <span style="color:#268bd2">CLUSTER_NAME</span><span style="color:#719e07">=</span>my-kafka-cluster
kubectl get pod/<span style="color:#2aa198">${</span><span style="color:#268bd2">CLUSTER_NAME</span><span style="color:#2aa198">}</span>-kafka-0 -o yaml
</code></pre></div><p>If you look into the <code>kafka</code> <code>container</code> section, you will notice the following:</p>
<p>One of the <code>volumes</code> configuration:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">  <span style="color:#268bd2">volumes</span>:
  - <span style="color:#268bd2">name</span>: data
    <span style="color:#268bd2">persistentVolumeClaim</span>:
      <span style="color:#268bd2">claimName</span>: data-my-kafka-cluster-kafka-0
</code></pre></div><p>The <code>volume</code> named <code>data</code> is associated with the <code>data-my-kafka-cluster-kafka-0</code> PVC, and the corresponding <code>volumeMounts</code> uses this volume to ensure that Kafka data is stored in <code>/var/lib/kafka/data</code></p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">    <span style="color:#268bd2">volumeMounts</span>:
    - <span style="color:#268bd2">mountPath</span>: /var/lib/kafka/data
      <span style="color:#268bd2">name</span>: data
</code></pre></div><p>To see the contents,</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#b58900">export</span> <span style="color:#268bd2">STRIMZI_BROKER_ID</span><span style="color:#719e07">=</span><span style="color:#2aa198">0</span>
kubectl <span style="color:#b58900">exec</span> -it my-kafka-cluster-kafka-0 -- ls -lrt /var/lib/kafka/data/kafka-log<span style="color:#2aa198">${</span><span style="color:#268bd2">STRIMZI_BROKER_ID</span><span style="color:#2aa198">}</span>
</code></pre></div><blockquote>
<p>You can repeat the same for Zookeeper node as well</p>
</blockquote>
<h3 id="what-about-the-cloud">&hellip;what about the Cloud?</h3>
<p>As mentioned before, in case of AKS, the data will end up being stored in an Azure Managed Disk. The type of disk is as per the <code>default</code> storage class in your AKS cluster. In my case, it is:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl get sc

azurefile           kubernetes.io/azure-file   58d
azurefile-premium   kubernetes.io/azure-file   58d
default <span style="color:#719e07">(</span>default<span style="color:#719e07">)</span>   kubernetes.io/azure-disk   2d18h
managed-premium     kubernetes.io/azure-disk   2d18h

//to get details of the storage class
kubectl get sc/default -o yaml
</code></pre></div><blockquote>
<p>More on the semantics for <code>default</code> storage class in <code>AKS</code> <a href="https://docs.microsoft.com/azure/aks/concepts-storage?WT.mc_id=devto-blog-abhishgu">in the documentation</a></p>
</blockquote>
<p>To query the disk in Azure, extract the <code>PersistentVolume</code> info using <code>kubectl get pv/&lt;name of kafka pv&gt; -o yaml</code> and get the ID of the Azure Disk i.e. <code>spec.azureDisk.diskURI</code></p>
<p>You can use the Azure CLI command <a href="https://docs.microsoft.com/cli/azure/disk?view=azure-cli-latest&amp;WT.mc_id=devto-blog-abhishgu#az-disk-show"><code>az disk show</code></a> command</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">az disk show --ids &lt;diskURI value&gt;
</code></pre></div><p>You will see that the storage type as defined in <code>sku</code> section is <code>StandardSSD_LRS</code> which corresponds to a <a href="https://docs.microsoft.com/azure/virtual-machines/windows/disks-types?WT.mc_id=devto-blog-abhishgu#standard-ssd">Standard SSD</a></p>
<blockquote>
<p>This table provides a comparison of different <a href="https://docs.microsoft.com/azure/virtual-machines/windows/disks-types?WT.mc_id=devto-blog-abhishgu#disk-comparison">Azure Disk types</a></p>
</blockquote>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">  <span style="color:#2aa198">&#34;sku&#34;</span>: {
    <span style="color:#268bd2">&#34;name&#34;</span>: <span style="color:#2aa198">&#34;StandardSSD_LRS&#34;</span>,
    <span style="color:#268bd2">&#34;tier&#34;</span>: <span style="color:#2aa198">&#34;Standard&#34;</span>
  }
</code></pre></div><p>&hellip; and the <code>tags</code> attribute highlight the <code>PV</code> and <code>PVC</code> association</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-json" data-lang="json">  <span style="color:#2aa198">&#34;tags&#34;</span>: {
    <span style="color:#268bd2">&#34;created-by&#34;</span>: <span style="color:#2aa198">&#34;kubernetes-azure-dd&#34;</span>,
    <span style="color:#268bd2">&#34;kubernetes.io-created-for-pv-name&#34;</span>: <span style="color:#2aa198">&#34;pvc-b4ece32b-a46c-4fbc-9b58-9413eee9c779&#34;</span>,
    <span style="color:#268bd2">&#34;kubernetes.io-created-for-pvc-name&#34;</span>: <span style="color:#2aa198">&#34;data-my-kafka-cluster-kafka-0&#34;</span>,
    <span style="color:#268bd2">&#34;kubernetes.io-created-for-pvc-namespace&#34;</span>: <span style="color:#2aa198">&#34;default&#34;</span>
  }
</code></pre></div><blockquote>
<p>You can repeat the same for Zookeeper disks as well</p>
</blockquote>
<h2 id="quick-test-">Quick test &hellip;</h2>
<p>Follow these steps to confirm that the cluster is working as expected..</p>
<p>Create a producer <code>Pod</code>:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#b58900">export</span> <span style="color:#268bd2">KAFKA_CLUSTER_NAME</span><span style="color:#719e07">=</span>my-kafka-cluster

kubectl run kafka-producer -ti --image<span style="color:#719e07">=</span>strimzi/kafka:latest-kafka-2.4.0 --rm<span style="color:#719e07">=</span><span style="color:#b58900">true</span> --restart<span style="color:#719e07">=</span>Never -- bin/kafka-console-producer.sh --broker-list <span style="color:#268bd2">$KAFKA_CLUSTER_NAME</span>-kafka-bootstrap:9092 --topic my-topic
</code></pre></div><p>In another terminal, create a consumer <code>Pod</code>:</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#b58900">export</span> <span style="color:#268bd2">KAFKA_CLUSTER_NAME</span><span style="color:#719e07">=</span>my-kafka-cluster

kubectl run kafka-consumer -ti --image<span style="color:#719e07">=</span>strimzi/kafka:latest-kafka-2.4.0 --rm<span style="color:#719e07">=</span><span style="color:#b58900">true</span> --restart<span style="color:#719e07">=</span>Never -- bin/kafka-console-consumer.sh --bootstrap-server <span style="color:#268bd2">$KAFKA_CLUSTER_NAME</span>-kafka-bootstrap:9092 --topic my-topic --from-beginning
</code></pre></div><h2 id="what-ifs-">What if(s) &hellip;</h2>
<p>Let&rsquo;s explore how to tackle a couple of requirements which you&rsquo;ll come across:</p>
<ul>
<li>Using a different storage type - In case of Azure for example, you might want to use <a href="https://docs.microsoft.com/azure/virtual-machines/windows/disks-types?WT.mc_id=devto-blog-abhishgu#premium-ssd">Azure Premium SSD</a> for production workloads</li>
<li>Re-sizing the storage - at some point you&rsquo;ll want to add storage to your Kafka cluster</li>
</ul>
<h3 id="change-the-storage-type">Change the storage type</h3>
<p>Recall that the default behavior is for Strimzi to create a <code>PersistentVolumeClaim</code> that references the <code>default</code> Storage Class. To customize this, you can simply include the <code>class</code> attribute in the <code>storage</code> specification in <code>spec.kafka</code> (and/or <code>spec.zookeeper</code>).</p>
<p>In Azure, the <code>managed-premium storage</code> class corresponds to a Premium SSD: <code>kubectl get sc/managed-premium -o yaml</code></p>
<p>Here is a snippet from the storage config, where <code>class: managed-premium</code> has been added.</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">    <span style="color:#268bd2">storage</span>:
      <span style="color:#268bd2">type</span>: persistent-claim
      <span style="color:#268bd2">size</span>: 2Gi
      <span style="color:#268bd2">deleteClaim</span>: <span style="color:#cb4b16">true</span>
      <span style="color:#268bd2">class</span>: managed-premium
</code></pre></div><p>Please note that you cannot update the storage type for an existing cluster. To try this out:</p>
<ul>
<li>Delete the existing cluster - <code>kubectl delete kafka/my-kafka-cluster</code> (wait for a while)</li>
<li>Create a new cluster - <code>kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-4/kafka-persistent-premium.yaml</code></li>
</ul>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">//Delete the existing cluster
kubectl delete kafka/my-kafka-cluster

//Create a new cluster
kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-4/kafka-persistent-premium.yaml
</code></pre></div><p>To confirm, check the <code>PersistentVolumeClain</code> for Kafka node - notice the <code>STORAGECLASS</code> colum</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">kubectl get pvc/data-my-kafka-cluster-kafka-0

NAME                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE
data-my-kafka-cluster-kafka-0   Bound    pvc-3f46d6ed-9da5-4c49-87ef-86684ab21cf8   2Gi        RWO            managed-premium   21s
</code></pre></div><blockquote>
<p>We only configured the Kafka broker to use the Premium storage, so the Zookeeper <code>Pod</code> will use the <code>StandardSSD</code> storage type.</p>
</blockquote>
<h3 id="re-size-storage-tldr---does-not-work-yet">Re-size storage (TL;DR - does not work yet)</h3>
<p>Azure Disks allow you to add more storage to it. In the case of Kubernetes, it is the storage class which defines whether this is supported or not - for AKS, if you check the default (or the <code>managed-premium</code>) storage class, you will notice the property <code>allowVolumeExpansion: true</code>, which confirms that you can do so in the context of Kubernetes PVC as well.</p>
<p>Strimzi makes it really easy to increase the storage for our Kafka cluster - all you need to do is update the <code>storage.size</code> field to the desired value</p>
<p>Check the PVC now: <code>kubectl describe pvc data-my-kafka-cluster-kafka-0</code></p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">Conditions:
  Type       Status  LastProbeTime                     LastTransitionTime                Reason  Message
  ----       ------  -----------------                 ------------------                ------  -------
  Resizing   True    Mon, 01 Jan 0001 00:00:00 +0000   Mon, 22 Jun 2020 23:15:26 +0530           
Events:
  Type     Reason              Age                From           Message
  ----     ------              ----               ----           -------
  Warning  VolumeResizeFailed  3s (x11 over 13s)  volume_expand  error expanding volume &#34;default/data-my-kafka-cluster-kafka-0&#34; of plugin &#34;kubernetes.io/azure-disk&#34;: compute.DisksClient#CreateOrUpdate: Failure sending request: StatusCode=0 -- Original Error: autorest/azure: Service returned an error. Status=&lt;nil&gt; Code=&#34;OperationNotAllowed&#34; Message=&#34;Cannot resize disk kubernetes-dynamic-pvc-3f46d6ed-9da5-4c49-87ef-86684ab21cf8 while it is attached to running VM /subscriptions/9a42a42f-ae42-4242-b6a7-dda0ea91d342/resourceGroups/mc_my-k8s-vk_southeastasia/providers/Microsoft.Compute/virtualMachines/aks-agentpool-42424242-1. Resizing a disk of an Azure Virtual Machine requires the virtual machine to be deallocated. Please stop your VM and retry the operation.&#34;
</code></pre></div><p>Notice the <code>&quot;Cannot resize disk...</code> error message. This is happening because the Azure Disk is currently attached with AKS cluster node and that is because of the <code>Pod</code> is associated with the <code>PersistentVolumeClaim</code> - this <a href="https://docs.microsoft.com/azure/virtual-machines/linux/expand-disks?WT.mc_id=devto-blog-abhishgu">is a documented limitation</a></p>
<p>I am not the first one to run into this problem of course. Please refer to <a href="https://github.com/kubernetes/kubernetes/issues/68427">issues such as this one</a> for details.</p>
<blockquote>
<p>There are workarounds but they have not been discussed in this blog. I included the section since I wanted you to be aware of this caveat</p>
</blockquote>
<h2 id="final-countdown-">Final countdown &hellip;</h2>
<p>We want to leave on a high note, don&rsquo;t we? Alright, so to wrap it up, let&rsquo;s scale our cluster out from one to three nodes. It&rsquo;d dead simple!</p>
<p>All you need to do is to increase the replicas to the desired number - in this case, I configured it to 3 (for Kafka and Zookeeper)</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">...
<span style="color:#268bd2">spec</span>:
  <span style="color:#268bd2">kafka</span>:
    <span style="color:#268bd2">version</span>: <span style="color:#2aa198">2.4.0</span>
    <span style="color:#268bd2">replicas</span>: <span style="color:#2aa198">3</span>
  <span style="color:#268bd2">zookeeper</span>:
    <span style="color:#268bd2">replicas</span>: <span style="color:#2aa198">3</span>
...
</code></pre></div><p>In addition to this, I also added an external load balancer listener (this will create an Azure Load Balancer, as discussed in <a href="https://dev.to/azure/kafka-on-kubernetes-the-strimzi-way-part-2-1210">part 2</a>)</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">...
    <span style="color:#268bd2">listeners</span>:
      <span style="color:#268bd2">plain</span>: {}
      <span style="color:#268bd2">external</span>:
        <span style="color:#268bd2">type</span>: loadbalancer
...
</code></pre></div><p>To create the new, simply use the new manifest</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-4/kafka-persistent-multi-node.yaml
</code></pre></div><blockquote>
<p>Please note that the overall cluster readiness will take time since there will be additional components (Azure Disks, Load Balancer public IPs etc.) that&rsquo;ll be created prior to the Pods being activated</p>
</blockquote>
<h3 id="in-your-k8s-cluster-you-will-see">In your k8s cluster, you will see&hellip;</h3>
<p>Three Pods each for Kafka and Zookeeper</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pod -l<span style="color:#719e07">=</span>app.kubernetes.io/instance<span style="color:#719e07">=</span>my-kafka-cluster

NAME                           READY   STATUS    RESTARTS   AGE
my-kafka-cluster-kafka-0       2/2     Running   <span style="color:#2aa198">0</span>          54s
my-kafka-cluster-kafka-1       2/2     Running   <span style="color:#2aa198">0</span>          54s
my-kafka-cluster-kafka-2       2/2     Running   <span style="color:#2aa198">0</span>          54s
my-kafka-cluster-zookeeper-0   1/1     Running   <span style="color:#2aa198">0</span>          4m44s
my-kafka-cluster-zookeeper-1   1/1     Running   <span style="color:#2aa198">0</span>          4m44s
my-kafka-cluster-zookeeper-2   1/1     Running   <span style="color:#2aa198">0</span>          4m44s
</code></pre></div><p>Three pairs (each for Kafka and Zookeeper) of PersistentVolumeClaims &hellip;</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get pvc

NAME                                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE
data-my-kafka-cluster-kafka-0       Bound    pvc-0f52dee1-970a-4c55-92bd-a97dcc41aee6   3Gi        RWO            managed-premium   10m
data-my-kafka-cluster-kafka-1       Bound    pvc-f8b613cb-3da0-4932-acea-7e5e96df1433   3Gi        RWO            managed-premium   4m24s
data-my-kafka-cluster-kafka-2       Bound    pvc-fedf431c-d87a-4bf7-80d0-d43b1337c079   3Gi        RWO            managed-premium   4m24s
data-my-kafka-cluster-zookeeper-0   Bound    pvc-1fda3714-3c37-428f-9e4b-bdb5da71cda6   1Gi        RWO            default           12m
data-my-kafka-cluster-zookeeper-1   Bound    pvc-702556e0-890a-4c07-ae5c-e2354d74d006   1Gi        RWO            default           6m42s
data-my-kafka-cluster-zookeeper-2   Bound    pvc-176ffd68-7e3a-4e04-abb1-52c54dcb84f0   1Gi        RWO            default           6m42s
</code></pre></div><p>&hellip; and the respective PersistentVolumes they are bound to</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                                       STORAGECLASS      REASON   AGE
pvc-0f52dee1-970a-4c55-92bd-a97dcc41aee6   3Gi        RWO            Delete           Bound       default/data-my-kafka-cluster-kafka-0       managed-premium            12m
pvc-176ffd68-7e3a-4e04-abb1-52c54dcb84f0   1Gi        RWO            Delete           Bound       default/data-my-kafka-cluster-zookeeper-2   default                    8m45s
pvc-1fda3714-3c37-428f-9e4b-bdb5da71cda6   1Gi        RWO            Delete           Bound       default/data-my-kafka-cluster-zookeeper-0   default                    14m
pvc-702556e0-890a-4c07-ae5c-e2354d74d006   1Gi        RWO            Delete           Bound       default/data-my-kafka-cluster-zookeeper-1   default                    8m45s
pvc-f8b613cb-3da0-4932-acea-7e5e96df1433   3Gi        RWO            Delete           Bound       default/data-my-kafka-cluster-kafka-1       managed-premium            6m27s
pvc-fedf431c-d87a-4bf7-80d0-d43b1337c079   3Gi        RWO            Delete           Bound       default/data-my-kafka-cluster-kafka-2       managed-premium            6m22s
</code></pre></div><p>&hellip; and Load Balancer IPs. Notice that these are created for each Kafka broker as well as a bootstrap IP which is recommended when connecting from client applications.</p>
<div class="highlight"><pre style="color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get svc -l<span style="color:#719e07">=</span>app.kubernetes.io/instance<span style="color:#719e07">=</span>my-kafka-cluster

NAME                                        TYPE           CLUSTER-IP     EXTERNAL-IP      PORT<span style="color:#719e07">(</span>S<span style="color:#719e07">)</span>                      AGE
my-kafka-cluster-kafka-0                    LoadBalancer   10.0.11.154    40.119.248.164   9094:30977/TCP               10m
my-kafka-cluster-kafka-1                    LoadBalancer   10.0.146.181   20.43.191.219    9094:30308/TCP               10m
my-kafka-cluster-kafka-2                    LoadBalancer   10.0.223.202   40.119.249.20    9094:30313/TCP               10m
my-kafka-cluster-kafka-bootstrap            ClusterIP      10.0.208.187   &lt;none&gt;           9091/TCP,9092/TCP            16m
my-kafka-cluster-kafka-brokers              ClusterIP      None           &lt;none&gt;           9091/TCP,9092/TCP            16m
my-kafka-cluster-kafka-external-bootstrap   LoadBalancer   10.0.77.213    20.43.191.238    9094:31051/TCP               10m
my-kafka-cluster-zookeeper-client           ClusterIP      10.0.3.155     &lt;none&gt;           2181/TCP                     18m
my-kafka-cluster-zookeeper-nodes            ClusterIP      None           &lt;none&gt;           2181/TCP,2888/TCP,3888/TCP   18m
</code></pre></div><p>To access the cluster, you can use the steps outlined in <a href="https://dev.to/azure/kafka-on-kubernetes-the-strimzi-way-part-2-1210">part 2</a></p>
<h2 id="its-a-wrap">It&rsquo;s a wrap!</h2>
<p>That&rsquo;s it for this blog series on which covered some of the aspects of running Kafka on Kubernetes using the open source Strimzi operator.</p>
<p>If this topic is of interest to you, I encourage you to check out other solutions such as <a href="https://docs.confluent.io/current/installation/operator/index.html">Confluent operator</a> and <a href="https://github.com/banzaicloud/kafka-operator">Banzai Cloud Kafka operator</a></p>

		</div>

		<div class="post-tags">
			
				
					<nav class="nav tags">
							<ul class="flat">
								
								<li><a href="/abhirockzz.github.io/tags/kafka">kafka</a></li>
								
								<li><a href="/abhirockzz.github.io/tags/kubernetes">kubernetes</a></li>
								
								<li><a href="/abhirockzz.github.io/tags/strimzi">strimzi</a></li>
								
							</ul>
					</nav>
				
			
		</div>
		</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> Â© Copyright notice |  <a href="https://github.com/vividvilla/ezhil">Ezhil theme</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-54762029-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<script>feather.replace()</script>
</body>
</html>
