<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Kafka on Kubernetes, the Strimzi way! (Part 3) - Data Foo</title>
  <meta name="description" content="Welcome to part three of this blog series!">
  <meta name="author" content="Abhishek Gupta"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Data Foo",
    
    "url": "https:\/\/abhirockzz.github.io\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/abhirockzz.github.io\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/abhirockzz.github.io\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/abhirockzz.github.io\/posts\/kafka-kubernetes-strimzi-3\/",
          "name": "Kafka on kubernetes, the strimzi way! ( part 3)"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Abhishek Gupta"
  },
  "headline": "Kafka on Kubernetes, the Strimzi way! (Part 3)",
  "description" : "Welcome to part three of this blog series!",
  "inLanguage" : "en",
  "wordCount":  2060 ,
  "datePublished" : "2020-07-07T00:00:00",
  "dateModified" : "2020-07-07T00:00:00",
  "image" : "https:\/\/abhirockzz.github.io\/icon.jpg",
  "keywords" : [ "kafka, kubernetes, strimzi" ],
  "mainEntityOfPage" : "https:\/\/abhirockzz.github.io\/posts\/kafka-kubernetes-strimzi-3\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/abhirockzz.github.io\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/abhirockzz.github.io\/icon.jpg",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="Kafka on Kubernetes, the Strimzi way! (Part 3)" />
<meta property="og:description" content="Welcome to part three of this blog series!">
<meta property="og:image" content="https://abhirockzz.github.io/icon.jpg" />
<meta property="og:url" content="https://abhirockzz.github.io/posts/kafka-kubernetes-strimzi-3/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Data Foo" />

  <meta name="twitter:title" content="Kafka on Kubernetes, the Strimzi way! (Part 3)" />
  <meta name="twitter:description" content="Welcome to part three of this blog series!">
  <meta name="twitter:image" content="https://abhirockzz.github.io/icon.jpg" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@abhi_tweeter" />
  <meta name="twitter:creator" content="@abhi_tweeter" />
  <link href='https://abhirockzz.github.io/icons/myicon.png' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.80.0" />
  <link rel="alternate" href="https://abhirockzz.github.io/index.xml" type="application/rss+xml" title="Data Foo"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://abhirockzz.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" /><link rel="stylesheet" href="https://abhirockzz.github.io/css/syntax.css" /><link rel="stylesheet" href="https://abhirockzz.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-54762029-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://abhirockzz.github.io/">Data Foo</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/about">About</a>
            </li>
          
        
          
            <li>
              <a title="Books" href="/books">Books</a>
            </li>
          
        
          
            <li>
              <a title="Presentations" href="/presentations">Presentations</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        

        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Data Foo" href="https://abhirockzz.github.io/">
            <img class="avatar-img" src="https://abhirockzz.github.io/icon.jpg" alt="Data Foo" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="posts-heading">
              
                <h1>Kafka on Kubernetes, the Strimzi way! (Part 3)</h1>
              
              
                <hr class="small">
              
              
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <p>Over the course of the first two parts of this blog series, we setup a single-node Kafka cluster on Kubernetes, secured it using TLS encryption and accessed the broker using both internal and external clients. Let&rsquo;s keep iterating! In this post, we will continue the Kafka on Kubernetes journey with Strimzi and cover:</p>
<ul>
<li>How to apply different authentication types: <code>TLS</code> and <code>SASL SCRAM-SHA-512</code></li>
<li>Use Strimzi Entity operator to manage Kafka users and topics</li>
<li>How to configure Kafka CLI and Go client applications to securely connect to the Kafka cluster</li>
</ul>
<blockquote>
<p>The code is available on GitHub - <a href="https://github.com/abhirockzz/kafka-kubernetes-strimzi/">https://github.com/abhirockzz/kafka-kubernetes-strimzi/</a></p>
</blockquote>
<h2 id="what-do-i-need-to-go-through-this-tutorial">What do I need to go through this tutorial?</h2>
<p><code>kubectl</code> - <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">https://kubernetes.io/docs/tasks/tools/install-kubectl/</a></p>
<p>I will be using <a href="https://docs.microsoft.com/azure/aks/intro-kubernetes?WT.mc_id=devto-blog-abhishgu">Azure Kubernetes Service (AKS)</a> to demonstrate the concepts, but by and large it is independent of the Kubernetes provider (e.g. feel free to use a local setup such as <code>minikube</code>). If you want to use <code>AKS</code>, all you need is a <a href="https://docs.microsoft.com/azure/?WT.mc_id=devto-blog-abhishgu">Microsoft Azure account</a> which you can <a href="https://azure.microsoft.com/free/?WT.mc_id=devto-blog-abhishgu">get for FREE</a> if you don&rsquo;t have one already.</p>
<blockquote>
<p>I will not be repeating some of the common sections (such as Installation/Setup (Helm, Strimzi, Azure Kubernetes Service), Strimzi overview) in this or subsequent part of this series and would request you to <a href="https://dev.to/azure/kafka-on-kubernetes-the-strimzi-way-part-1-57g7">refer to part one</a></p>
</blockquote>
<h2 id="create-a-kafka-cluster-with-tls-authentication">Create a Kafka cluster with TLS authentication</h2>
<p>To enforce 2-way mutual <code>TLS</code> auth, all we need to do is tweak the Strimzi <code>Kafka</code> resource. I am highlighting the key part below. The other parts remain the same (<a href="https://github.com/abhirockzz/kafka-kubernetes-strimzi/raw/master/part-2/kafka.yaml">here is the manifest from part 2</a>) i.e. single node Kafka and Zookeeper, ephemeral storage along with <code>TLS</code> encryption</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">      </span><span class="nt">external</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">loadbalancer</span><span class="w">
</span><span class="w">        </span><span class="nt">tls</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">        </span><span class="nt">authentication</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">tls</span><span class="w">
</span></code></pre></div><p>All we did is all the <code>tls</code> authentication type as a property of the <code>external</code> listener. In addition to this, we also include the <code>entityOperator</code> configuration as such:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">  </span><span class="nt">entityOperator</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">userOperator</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span><span class="w">    </span><span class="nt">topicOperator</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span></code></pre></div><p>This activates the Strimzi <code>Entity Operator</code> which in turn comprises of the <code>Topic Operator</code> and <code>User Operator</code>. Just as the <code>Kafka</code> CRD allows you to control Kafka clusters on Kubernetes, a Topic Operator allows you to manage topics in a Kafka cluster through a custom resource called <code>KafkaTopic</code> i.e. you can create, delete and update topics in your Kafka cluster.</p>
<blockquote>
<p>The interesting part is that it&rsquo;s a two-way sync i.e. you can still create topics by accessing the Kafka cluster directly and it would reflect in the <code>KafkaTopic</code> resources being created/updated/deleted</p>
</blockquote>
<p>The goal of the User Operator is to make Kafka user management easier with help of a <code>KafkaUser</code> CRD. All you do is create instances of <code>KafkaUser</code> CRDs and Strimzi takes care of the Kafka specific user management parts</p>
<blockquote>
<p>Unlike Topic Operator, this is not a two-way sync</p>
</blockquote>
<p>Read more about Entity Operator here <a href="https://strimzi.io/docs/operators/master/using.html#assembly-kafka-entity-operator-deployment-configuration-kafka">https://strimzi.io/docs/operators/master/using.html#assembly-kafka-entity-operator-deployment-configuration-kafka</a></p>
<p>We will dive into the practical bit of these two operators in upcoming sections.</p>
<p>To create the Kafka cluster:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-3/kafka-tls-auth.yaml
</code></pre></div><p><strong>What did the Strimzi Operator do for us in this case?</strong></p>
<p>We covered most of these in <a href="https://dev.to/azure/kafka-on-kubernetes-the-strimzi-way-part-1-57g7">part 1</a> - <code>StatefulSet</code> (and <code>Pods</code>), <code>LoadBalancer</code> Service, <code>ConfigMap</code>, <code>Secret</code> etc. How is the <code>TLS</code> auth config enforced? To figure that out, let&rsquo;s introspect the Kafka server configuration</p>
<blockquote>
<p>As explained in part 1, this is stored in a <code>ConfigMap</code></p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">CLUSTER_NAME</span><span class="o">=</span>my-kafka-cluster
kubectl get configmap/<span class="si">${</span><span class="nv">CLUSTER_NAME</span><span class="si">}</span>-kafka-config -o yaml
</code></pre></div><p>Look at the <code>External listener</code> section in <code>server.config</code>:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">    listener.name.external-9094.ssl.client.auth<span class="o">=</span>required
    listener.name.external-9094.ssl.truststore.location<span class="o">=</span>/tmp/kafka/clients.truststore.p12
    listener.name.external-9094.ssl.truststore.password<span class="o">=</span><span class="si">${</span><span class="nv">CERTS_STORE_PASSWORD</span><span class="si">}</span>
    listener.name.external-9094.ssl.truststore.type<span class="o">=</span>PKCS12
</code></pre></div><p>The snippet highlighted above is the part which was added - notice <code>listener.name.external-9094.ssl.client.auth=required</code> was added along with the truststore details.</p>
<p><strong>Let&rsquo;s not forget the Entity Operator</strong></p>
<p>The Entity Operator runs a separate <code>Deployment</code></p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">CLUSTER_NAME</span><span class="o">=</span>my-kafka-cluster
kubectl get deployment <span class="nv">$CLUSTER_NAME</span>-entity-operator
kubectl get pod -l<span class="o">=</span>app.kubernetes.io/name<span class="o">=</span>entity-operator

NAME                                                READY   STATUS     
my-kafka-cluster-entity-operator-666f8758f6-gj54h   3/3     Running         
</code></pre></div><p>The entity operator <code>Pod</code> runs three containers - topic-operator, user-operator, tls-sidecar</p>
<p>We have configured our cluster to authenticate client connections, but what about the user credentials which will be used by client apps?</p>
<h2 id="time-to-use-the-user-operator">Time to use the User Operator!</h2>
<p>The User Operator allows us to create <code>KafkaUser</code>s to represent client authentication credentials. As mentioned in the beginning of the blog post, supported authentication types include <code>TLS</code> and <code>SCRAM-SHA-512</code>. Behind the scenes, a Kubernetes <code>Secret</code> is created by Strimzi to store the credentials</p>
<blockquote>
<p>OAuth 2.0 is also supported but its not handled by the User Operator</p>
</blockquote>
<p>Let&rsquo;s create a <code>KafkaUser</code> to store client credentials for TLS auth. Here is what the user info looks like:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kafka.strimzi.io/v1beta1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KafkaUser</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">kafka-tls-client-credentials</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">strimzi.io/cluster</span><span class="p">:</span><span class="w"> </span><span class="l">my-kafka-cluster</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">authentication</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">tls</span><span class="w">
</span></code></pre></div><p>We name the user <code>kafka-tls-client-credentials</code>, associate with the Kafka cluster we created earlier (using the label <code>strimzi.io/cluster: my-kafka-cluster</code>) and specify the <code>tls</code> authentication type</p>
<blockquote>
<p>You can also define authorization rules (not covered in this blog) within a <code>KafkaUser</code> definition - see <a href="https://strimzi.io/docs/operators/master/using.html#type-KafkaUser-reference">https://strimzi.io/docs/operators/master/using.html#type-KafkaUser-reference</a></p>
</blockquote>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-3/user-tls-auth.yaml
</code></pre></div><p>Introspect the <code>Secret</code> (it has the same name as the <code>KafkaUser</code>):</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl get secret/kafka-tls-client-credentials -o yaml
</code></pre></div><h2 id="tls-client-authentication">TLS client authentication</h2>
<p>That&rsquo;s it! Now its up to the client to use the credentials. We will use a Kafka CLI and Go client application to try this out. First things first:</p>
<p><strong>Extract and configure the user credentials</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">KAFKA_USER_NAME</span><span class="o">=</span>kafka-tls-client-credentials
kubectl get secret <span class="nv">$KAFKA_USER_NAME</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.user\.crt}&#39;</span> <span class="p">|</span> base64 --decode &gt; user.crt
kubectl get secret <span class="nv">$KAFKA_USER_NAME</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.user\.key}&#39;</span> <span class="p">|</span> base64 --decode &gt; user.key
kubectl get secret <span class="nv">$KAFKA_USER_NAME</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.user\.p12}&#39;</span> <span class="p">|</span> base64 --decode &gt; user.p12
kubectl get secret <span class="nv">$KAFKA_USER_NAME</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.user\.password}&#39;</span> <span class="p">|</span> base64 --decode &gt; user.password
</code></pre></div><p>Import the entry in <code>user.p12</code> into another keystore</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">USER_P12_FILE_PATH</span><span class="o">=</span>user.p12
<span class="nb">export</span> <span class="nv">USER_KEY_PASSWORD_FILE_PATH</span><span class="o">=</span>user.password
<span class="nb">export</span> <span class="nv">KEYSTORE_NAME</span><span class="o">=</span>kafka-auth-keystore.jks
<span class="nb">export</span> <span class="nv">KEYSTORE_PASSWORD</span><span class="o">=</span>foobar
<span class="nb">export</span> <span class="nv">PASSWORD</span><span class="o">=</span><span class="sb">`</span>cat <span class="nv">$USER_KEY_PASSWORD_FILE_PATH</span><span class="sb">`</span>

sudo keytool -importkeystore -deststorepass <span class="nv">$KEYSTORE_PASSWORD</span> -destkeystore <span class="nv">$KEYSTORE_NAME</span> -srckeystore <span class="nv">$USER_P12_FILE_PATH</span> -srcstorepass <span class="nv">$PASSWORD</span> -srcstoretype PKCS12

sudo keytool -list -alias <span class="nv">$KAFKA_USER_NAME</span> -keystore <span class="nv">$KEYSTORE_NAME</span>
</code></pre></div><p>Just like we did in <a href="https://dev.to/azure/kafka-on-kubernetes-the-strimzi-way-part-2-1210">part 2</a>, TLS encryption config requires importing the cluster CA cert in the client truststore</p>
<p><strong>Extract and configure server CA cert</strong></p>
<p>Extract the cluster CA certificate and password</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">CLUSTER_NAME</span><span class="o">=</span>my-kafka-cluster

kubectl get secret <span class="nv">$CLUSTER_NAME</span>-cluster-ca-cert -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.ca\.crt}&#39;</span> <span class="p">|</span> base64 --decode &gt; ca.crt
kubectl get secret <span class="nv">$CLUSTER_NAME</span>-cluster-ca-cert -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.ca\.password}&#39;</span> <span class="p">|</span> base64 --decode &gt; ca.password
</code></pre></div><p>Import it into <code>truststore</code> - I am using the built-in truststore which comes in with a JDK (Java) installation - but this is just for convenience and you&rsquo;re free to use other truststore</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">CERT_FILE_PATH</span><span class="o">=</span>ca.crt
<span class="nb">export</span> <span class="nv">CERT_PASSWORD_FILE_PATH</span><span class="o">=</span>ca.password

<span class="c1"># replace this with the path to your truststore</span>

<span class="nb">export</span> <span class="nv">KEYSTORE_LOCATION</span><span class="o">=</span>/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home/jre/lib/security/cacerts
<span class="nb">export</span> <span class="nv">PASSWORD</span><span class="o">=</span><span class="sb">`</span>cat <span class="nv">$CERT_PASSWORD_FILE_PATH</span><span class="sb">`</span>

<span class="c1"># you will prompted for the truststore password. for JDK truststore, the default password is &#34;changeit&#34;</span>
<span class="c1"># Type yes in response to the &#39;Trust this certificate? [no]:&#39; prompt</span>

sudo keytool -importcert -alias strimzi-kafka-cert -file <span class="nv">$CERT_FILE_PATH</span> -keystore <span class="nv">$KEYSTORE_LOCATION</span> -keypass <span class="nv">$PASSWORD</span>

sudo keytool -list -alias strimzi-kafka-cert -keystore <span class="nv">$KEYSTORE_LOCATION</span>
</code></pre></div><p>You should now be able to authenticate to the Kafka cluster using the Kafka CLI client</p>
<blockquote>
<p>Please note that the configuration steps for the Kafka CLI as detailed below will also work for the Java clients as well - feel free to try that out as well</p>
</blockquote>
<p><strong>Create properties file for Kafka CLI clients</strong></p>
<p>Extract the <code>LoadBalancer</code> public IP for Kafka cluster</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">KAFKA_CLUSTER_NAME</span><span class="o">=</span>my-kafka-cluster

kubectl get service/<span class="si">${</span><span class="nv">KAFKA_CLUSTER_NAME</span><span class="si">}</span>-kafka-external-bootstrap --output<span class="o">=</span><span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress<span class="o">[</span>0<span class="o">]</span>.ip<span class="o">}</span>
</code></pre></div><p>Create a file called <code>client-ssl-auth.properties</code> with the following contents:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">bootstrap.servers<span class="o">=[</span>LOADBALANCER_PUBLIC_IP<span class="o">]</span>:9094
security.protocol<span class="o">=</span>SSL
ssl.truststore.location<span class="o">=[</span>TRUSTSTORE_LOCATION<span class="o">]</span>
ssl.truststore.password<span class="o">=</span>changeit
ssl.keystore.location<span class="o">=</span>kafka-auth-keystore.jks
ssl.keystore.password<span class="o">=</span>foobar
ssl.key.password<span class="o">=[</span>contents of user.password file<span class="o">]</span>
</code></pre></div><blockquote>
<p><code>changeit</code> is the default truststore password. Please use a different one if needed</p>
</blockquote>
<p>Download Kafka if you don&rsquo;t have it already - <a href="https://kafka.apache.org/downloads">https://kafka.apache.org/downloads</a></p>
<p>One last thing before you proceed</p>
<p><strong>Create a <code>KafkaTopic</code></strong></p>
<p>As I mentioned earlier, the Topic Operator makes this possible to embed topic info in form of a <code>KafkaTopic</code> manifest as such:</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kafka.strimzi.io/v1beta1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KafkaTopic</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">strimzi-test-topic</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">strimzi.io/cluster</span><span class="p">:</span><span class="w"> </span><span class="l">my-kafka-cluster</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">partitions</span><span class="p">:</span><span class="w"> </span><span class="m">3</span><span class="w">
</span><span class="w">  </span><span class="nt">replicas</span><span class="p">:</span><span class="w"> </span><span class="m">1</span><span class="w">
</span></code></pre></div><p>To create the topic:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-3/topic.yaml
</code></pre></div><blockquote>
<p>Here is the reference for a <code>KafkaTopic</code> CRD <a href="https://strimzi.io/docs/operators/master/using.html#type-KafkaTopic-reference">https://strimzi.io/docs/operators/master/using.html#type-KafkaTopic-reference</a></p>
</blockquote>
<p>All you need to do is use the <code>kafka-console-producer</code> and <code>kafka-console-consumer</code> by pointing it to the <code>client-ssl-auth.properties</code> file you just created</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">KAFKA_HOME</span><span class="o">=[</span>replace with kafka installation<span class="o">]</span> e.g. /Users/foobar/kafka_2.12-2.3.0
<span class="nb">export</span> <span class="nv">LOADBALANCER_PUBLIC_IP</span><span class="o">=[</span>replace with public-ip<span class="o">]</span>
<span class="nb">export</span> <span class="nv">TOPIC_NAME</span><span class="o">=</span>strimzi-test-topic

<span class="c1"># on a terminal, start producer and send a few messages</span>
<span class="nv">$KAFKA_HOME</span>/bin/kafka-console-producer.sh --broker-list <span class="nv">$LOADBALANCER_PUBLIC_IP</span>:9094 --topic <span class="nv">$TOPIC_NAME</span> --producer.config client-ssl-auth.properties

<span class="c1"># on another terminal, start consumer</span>
<span class="nv">$KAFKA_HOME</span>/bin/kafka-console-consumer.sh --bootstrap-server <span class="nv">$LOADBALANCER_PUBLIC_IP</span>:9094 --topic <span class="nv">$TOPIC_NAME</span> --consumer.config client-ssl-auth.properties --from-beginning
</code></pre></div><p>You should see producer and consumer working in tandem. Great!</p>
<blockquote>
<p>If you face SSL Handshake errors, please check whether keys and certificates has been correctly imported and you&rsquo;re using the correct password. If the Kafka cluster is not reachable, ensure you are using the right value for the public IP</p>
</blockquote>
<p>Now, let&rsquo;s try a programmatic client. Since the Java client behavior (required config properties) are same as the CLI, I am using a Go client to try something different. Don&rsquo;t worry, if you are not a Go programmer, it should be easy to follow along.</p>
<p>I will not walk through the entire program, just the part where we create the connection related configuration. Here is the snippet:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go">    <span class="nx">bootstrapServers</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;KAFKA_BOOTSTRAP_SERVERS&#34;</span><span class="p">)</span>
    <span class="nx">caLocation</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;CA_CERT_LOCATION&#34;</span><span class="p">)</span>
    <span class="nx">topic</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;KAFKA_TOPIC&#34;</span><span class="p">)</span>

    <span class="nx">userCertLocation</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;USER_CERT_LOCATION&#34;</span><span class="p">)</span>
    <span class="nx">userKeyLocation</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;USER_KEY_LOCATION&#34;</span><span class="p">)</span>
    <span class="nx">userKeyPassword</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;USER_KEY_PASSWORD&#34;</span><span class="p">)</span>

    <span class="nx">producerConfig</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">kafka</span><span class="p">.</span><span class="nx">ConfigMap</span><span class="p">{</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="p">:</span> <span class="nx">bootstrapServers</span><span class="p">,</span> <span class="s">&#34;security.protocol&#34;</span><span class="p">:</span> <span class="s">&#34;SSL&#34;</span><span class="p">,</span> <span class="s">&#34;ssl.ca.location&#34;</span><span class="p">:</span> <span class="nx">caLocation</span><span class="p">,</span> <span class="s">&#34;ssl.certificate.location&#34;</span><span class="p">:</span> <span class="nx">userCertLocation</span><span class="p">,</span> <span class="s">&#34;ssl.key.location&#34;</span><span class="p">:</span> <span class="nx">userKeyLocation</span><span class="p">,</span> <span class="s">&#34;ssl.key.password&#34;</span><span class="p">:</span> <span class="nx">userKeyPassword</span><span class="p">}</span>
</code></pre></div><p>Notice that the <code>bootstrap.servers</code> and <code>security.protocol</code> are the same as ones you used in the Kafka CLI client (same for Java as well).</p>
<ul>
<li>For TLS encryption: <code>ssl.ca.location</code> is used to point to the CA certificate directly as opposed to a truststore</li>
<li>For client authentication: <code>ssl.certificate.location</code>, <code>ssl.key.location</code> and <code>ssl.key.password</code> refer to the user certificate, user key and password respectively</li>
</ul>
<p>If you have <code>Go</code> installed, you can try it out. Clone the Git repo</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">git clone https://github.com/abhirockzz/kafka-kubernetes-strimzi
<span class="nb">cd</span> part-3/go-client-app
</code></pre></div><p>.. and run the program:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go"><span class="nx">export</span> <span class="nx">KAFKA_BOOTSTRAP_SERVERS</span><span class="p">=[</span><span class="nx">replace</span> <span class="nx">with</span> <span class="nx">public</span><span class="o">-</span><span class="nx">ip</span><span class="p">:</span><span class="mi">9094</span><span class="p">]</span> <span class="nx">e</span><span class="p">.</span><span class="nx">g</span><span class="p">.</span> <span class="mf">20.43.176.7</span><span class="p">:</span><span class="mi">9094</span>
<span class="nx">export</span> <span class="nx">CA_CERT_LOCATION</span><span class="p">=[</span><span class="nx">replace</span> <span class="nx">with</span> <span class="nx">location</span> <span class="nx">of</span> <span class="nx">ca</span><span class="p">.</span><span class="nx">crt</span> <span class="nx">file</span><span class="p">]</span> <span class="nx">e</span><span class="p">.</span><span class="nx">g</span><span class="p">.</span> <span class="o">/</span><span class="nx">Users</span><span class="o">/</span><span class="nx">code</span><span class="o">/</span><span class="nx">kafka</span><span class="o">-</span><span class="nx">kubernetes</span><span class="o">-</span><span class="nx">strimzi</span><span class="o">/</span><span class="nx">part</span><span class="o">-</span><span class="mi">3</span><span class="o">/</span><span class="nx">ca</span><span class="p">.</span><span class="nx">crt</span>
<span class="nx">export</span> <span class="nx">KAFKA_TOPIC</span><span class="p">=</span><span class="nx">test</span><span class="o">-</span><span class="nx">strimzi</span><span class="o">-</span><span class="nx">topic</span>

<span class="nx">export</span> <span class="nx">USER_CERT_LOCATION</span><span class="p">=[</span><span class="nx">path</span> <span class="nx">to</span> <span class="nx">user</span><span class="p">.</span><span class="nx">crt</span> <span class="nx">file</span><span class="p">]</span> <span class="nx">e</span><span class="p">.</span><span class="nx">g</span><span class="p">.</span> <span class="o">/</span><span class="nx">Users</span><span class="o">/</span><span class="nx">code</span><span class="o">/</span><span class="nx">kafka</span><span class="o">-</span><span class="nx">kubernetes</span><span class="o">-</span><span class="nx">strimzi</span><span class="o">/</span><span class="nx">part</span><span class="o">-</span><span class="mi">3</span><span class="o">/</span><span class="nx">user</span><span class="p">.</span><span class="nx">crt</span>
<span class="nx">export</span> <span class="nx">USER_KEY_LOCATION</span><span class="p">=[</span><span class="nx">path</span> <span class="nx">to</span> <span class="nx">user</span><span class="p">.</span><span class="nx">key</span> <span class="nx">file</span><span class="p">]</span> <span class="nx">e</span><span class="p">.</span><span class="nx">g</span><span class="p">.</span> <span class="o">/</span><span class="nx">Users</span><span class="o">/</span><span class="nx">code</span><span class="o">/</span><span class="nx">kafka</span><span class="o">-</span><span class="nx">kubernetes</span><span class="o">-</span><span class="nx">strimzi</span><span class="o">/</span><span class="nx">part</span><span class="o">-</span><span class="mi">3</span><span class="o">/</span><span class="nx">user</span><span class="p">.</span><span class="nx">key</span>
<span class="nx">export</span> <span class="nx">USER_KEY_PASSWORD</span><span class="p">=[</span><span class="nx">contents</span> <span class="nx">of</span> <span class="nx">user</span><span class="p">.</span><span class="nx">password</span> <span class="nx">file</span><span class="p">]</span>

<span class="k">go</span> <span class="nx">run</span> <span class="nx">kafka</span><span class="o">-</span><span class="nx">tls</span><span class="o">-</span><span class="nx">auth</span><span class="o">-</span><span class="nx">client</span><span class="p">.</span><span class="k">go</span>
</code></pre></div><p>The logs should confirm whether messages are being produced and consumed</p>
<h2 id="enforce-scram-sha-512-auth">Enforce SCRAM-SHA-512 auth</h2>
<p><code>SCRAM</code> stands for &ldquo;Salted Challenge Response Authentication Mechanism&rdquo;. I will not pretend to be a security or <code>SCRAM</code> expert, but do want to highlight that it is one of the supported and commonly used authentication mechanism in Kafka (in addition to other such as <code>PLAIN</code>)</p>
<blockquote>
<p>Please note that Strimzi does not support <code>SASL PLAIN</code> auth at the time of writing</p>
</blockquote>
<p><strong>Update the Kafka cluster</strong></p>
<p>To apply the <code>SCRAM</code> authentication scheme - all you need is to set the <code>authentication.type</code> to <code>scram-sha-512</code></p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="w">      </span><span class="nt">external</span><span class="p">:</span><span class="w">
</span><span class="w">        </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">loadbalancer</span><span class="w">
</span><span class="w">        </span><span class="nt">tls</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span><span class="w">        </span><span class="nt">authentication</span><span class="p">:</span><span class="w">
</span><span class="w">          </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">scram-sha-512</span><span class="w">
</span></code></pre></div><p>Update the Kafka cluster to use <code>SCRAM-SHA</code> authentication</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-3/kafka-tls-auth.yaml
</code></pre></div><p>Let&rsquo;s take a look at how the Kafka server config looks like in this case:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">CLUSTER_NAME</span><span class="o">=</span>my-kafka-cluster
kubectl get configmap/<span class="si">${</span><span class="nv">CLUSTER_NAME</span><span class="si">}</span>-kafka-config -o yaml
</code></pre></div><p>Introspect <code>External listener</code> section in <code>server.config</code> and notice how the the config has been updated to reflect</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">    listener.name.external-9094.scram-sha-512.sasl.jaas.config<span class="o">=</span>org.apache.kafka.common.security.scram.ScramLoginModule required<span class="p">;</span>
    listener.name.external-9094.sasl.enabled.mechanisms<span class="o">=</span>SCRAM-SHA-512
</code></pre></div><p><strong>Create SCRAM credentials (<code>KafkaUser</code>)</strong></p>
<p>Just like we did with <code>TLS</code> auth, we need to create client credentials for <code>SCRAM</code> as well. It only differs from its TLS equivalent in terms of name and the type (of course!)</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kafka.strimzi.io/v1beta1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KafkaUser</span><span class="w">
</span><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">kafka-scram-client-credentials</span><span class="w">
</span><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">strimzi.io/cluster</span><span class="p">:</span><span class="w"> </span><span class="l">my-kafka-cluster</span><span class="w">
</span><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">authentication</span><span class="p">:</span><span class="w">
</span><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">scram-sha-512</span><span class="w">
</span></code></pre></div><blockquote>
<p>notice that <code>authentication.type</code> is <code>scram-sha-512</code></p>
</blockquote>
<p>Create the <code>KafkaUser</code></p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f https://raw.githubusercontent.com/abhirockzz/kafka-kubernetes-strimzi/master/part-3/user-scram-auth.yaml
</code></pre></div><p>Introspect the <code>Secret</code> (it has the same name as the <code>KafkaUser</code>):</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">kubectl get secret/kafka-scram-client-credentials -o yaml
</code></pre></div><p>The <code>Secret</code> contains the <code>password</code> in <code>base64</code> encoded form</p>
<div class="highlight"><pre class="chroma"><code class="language-yaml" data-lang="yaml"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Secret</span><span class="w">
</span><span class="w"></span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">kafka-scram-client-credentials</span><span class="w">
</span><span class="w"></span><span class="nt">data</span><span class="p">:</span><span class="w">
</span><span class="w">  </span><span class="nt">password</span><span class="p">:</span><span class="w"> </span><span class="l">SnpteEQwek1DNkdi</span><span class="w">
</span><span class="w"></span><span class="nn">...</span><span class="w">
</span></code></pre></div><blockquote>
<p>Username is same as the <code>KafkaUser</code>/<code>Secret</code> name, which is <code>kafka-scram-client-credentials</code> in this example</p>
</blockquote>
<p><strong>Run client applications</strong></p>
<p>In order run the client examples, download the the password:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">USER_NAME</span><span class="o">=</span>kafka-scram-client-credentials
kubectl get secret <span class="nv">$USER_NAME</span> -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.data.password}&#39;</span> <span class="p">|</span> base64 --decode &gt; user-scram.password
</code></pre></div><p>To test the Kafka CLI client, create a file <code>client-scram-auth.properties</code> with the following contents:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash">bootstrap.servers<span class="o">=[</span>replace with public-ip:9094<span class="o">]</span>
security.protocol<span class="o">=</span>SASL_SSL
sasl.mechanism<span class="o">=</span>SCRAM-SHA-512
ssl.truststore.location<span class="o">=[</span>replace with path to truststore with kafka CA cert<span class="o">]</span>
<span class="c1"># &#34;changeit&#34; is the default password for JDK truststore, please use the one applicable to yours</span>
ssl.truststore.password<span class="o">=</span>changeit
sasl.jaas.config<span class="o">=</span>org.apache.kafka.common.security.scram.ScramLoginModule required <span class="nv">username</span><span class="o">=</span><span class="s2">&#34;kafka-scram-client-credentials&#34;</span> <span class="nv">password</span><span class="o">=</span><span class="s2">&#34;[replace with contents of user-scram.password file]&#34;</span><span class="p">;</span>
</code></pre></div><p>Refer to the instructions above to run the console producer and consumer</p>
<blockquote>
<p>please make sure you use the <code>client-scram-auth.properties</code> and not the <code>client-tls-auth.properties</code> file</p>
</blockquote>
<p>Before wrapping up, lets look at the Go client and see how it handles <code>SCRAM</code> authentication. As always, I will only highlight the part which showcases the configuration:</p>
<div class="highlight"><pre class="chroma"><code class="language-go" data-lang="go">    <span class="nx">bootstrapServers</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;KAFKA_BOOTSTRAP_SERVERS&#34;</span><span class="p">)</span>
    <span class="nx">caLocation</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;CA_CERT_LOCATION&#34;</span><span class="p">)</span>
    <span class="nx">topic</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;KAFKA_TOPIC&#34;</span><span class="p">)</span>

    <span class="nx">kafkaScramUsername</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;SCRAM_USERNAME&#34;</span><span class="p">)</span>
    <span class="nx">kafkaScramPassword</span> <span class="p">=</span> <span class="nx">os</span><span class="p">.</span><span class="nf">Getenv</span><span class="p">(</span><span class="s">&#34;SCRAM_PASSWORD&#34;</span><span class="p">)</span>

    <span class="nx">producerConfig</span> <span class="o">:=</span> <span class="o">&amp;</span><span class="nx">kafka</span><span class="p">.</span><span class="nx">ConfigMap</span><span class="p">{</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="p">:</span> <span class="nx">bootstrapServers</span><span class="p">,</span> <span class="s">&#34;security.protocol&#34;</span><span class="p">:</span> <span class="s">&#34;SASL_SSL&#34;</span><span class="p">,</span> <span class="s">&#34;ssl.ca.location&#34;</span><span class="p">:</span> <span class="nx">caLocation</span><span class="p">,</span> <span class="s">&#34;sasl.mechanism&#34;</span><span class="p">:</span> <span class="s">&#34;SCRAM-SHA-512&#34;</span><span class="p">,</span> <span class="s">&#34;sasl.username&#34;</span><span class="p">:</span> <span class="nx">kafkaScramUsername</span><span class="p">,</span> <span class="s">&#34;sasl.password&#34;</span><span class="p">:</span> <span class="nx">kafkaScramPassword</span><span class="p">}</span>
</code></pre></div><p>The <code>security.protocol</code> and <code>sasl.mechanism</code> have been updated to <code>SASL_SSL</code> and <code>SCRAM-SHA-512</code> respectively. Along with that, we use the <code>sasl.username</code> and <code>sasl.password</code> to specify the client credentials</p>
<p>To run the <code>Go</code> client app:</p>
<div class="highlight"><pre class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">export</span> <span class="nv">KAFKA_BOOTSTRAP_SERVERS</span><span class="o">=[</span>replace with public-ip:9094<span class="o">]</span>
<span class="nb">export</span> <span class="nv">CA_CERT_LOCATION</span><span class="o">=[</span>path to ca.crt file<span class="o">]</span> f.g. /Users/code/kafka-kubernetes-strimzi/part-3/ca.crt
<span class="nb">export</span> <span class="nv">KAFKA_TOPIC</span><span class="o">=</span>strimzi-test-topic

<span class="nb">export</span> <span class="nv">SCRAM_USERNAME</span><span class="o">=</span>kafka-scram-client-credentials
<span class="nb">export</span> <span class="nv">SCRAM_PASSWORD</span><span class="o">=[</span>contents of user-scram.password file<span class="o">]</span>

go run kafka-scram-auth-client.go
</code></pre></div><h2 id="wrap-up-for-now">Wrap up.. for now</h2>
<p>This post covered a decent amount of ground! We learnt how to apply different authentication types, use Entity Operators to manage Kafka users and topics and more importantly, understand how client applications need to configured to connect securely using a combination of TLS encryption and the chosen authentication scheme.</p>
<p>We&rsquo;re far from done! All this while, we&rsquo;ve been creating <code>ephemeral</code> clusters with no persistence - we will fix that in upcoming posts.</p>


        
          <div class="blog-tags">
            
              <a href="https://abhirockzz.github.io//tags/kafka/">kafka</a>&nbsp;
            
              <a href="https://abhirockzz.github.io//tags/kubernetes/">kubernetes</a>&nbsp;
            
              <a href="https://abhirockzz.github.io//tags/strimzi/">strimzi</a>&nbsp;
            
          </div>
        

        

        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://abhirockzz.github.io/posts/postgres-kafka-debezium-azure-cdc/" data-toggle="tooltip" data-placement="top" title="Change Data Capture architecture using Debezium, Postgres and Kafka">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="https://abhirockzz.github.io/posts/manage-eventhubs-kubernetes/" data-toggle="tooltip" data-placement="top" title="Orchestrate Azure Event Hubs via Kubernetes">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
  </div>
</div>

      
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="https://github.com/abhirockzz" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/abhi_tweeter" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/abhirockzz" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              <a href="https://abhirockzz.github.io">Abhishek Gupta</a>
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2021
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://abhirockzz.github.io/">Data Foo</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.80.0</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="https://abhirockzz.github.io/js/main.js"></script><script> renderMathInElement(document.body); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://abhirockzz.github.io/js/load-photoswipe.js"></script>









    
  </body>
</html>

